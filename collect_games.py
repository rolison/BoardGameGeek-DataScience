import requests
from bs4 import BeautifulSoup
import time
import numpy as np

# Global Variables 

WAIT_TIME_BETWEEN_REQUESTS = 6 # seconds

BGG_SITE = 'https://boardgamegeek.com'

BGG_GAME_LIST_PAGE = 'https://boardgamegeek.com/browse/boardgame/page/'


def scrape_list_of_top_games(num_games, out_file_name = 'BGG_GameList.csv'):
    '''
    Go to boardgamegeek.com's board game browser and get data on the top ranked
    games on their site and save it to a CSV file. 

    num_games     : Number of games to scrape on the website ranking list.
                    (Type: integer)

    out_file_name : Name of the text file to be written.
                    (Type: String) 
         
    '''
    start_time = time.time()

    with open(out_file_name, 'w') as csv_file:

        # Convert to integer in case user provided a float
        # There are 100 games listed per page on bgg
        num_pages = int(num_games//100) + 1 

        # Write header information for csv 
        csv_file.write('Rank\tName\tHRef\tYear Published\tGeek Rating\t'+\
                                  'Average Rating\tNumber of Voters\n')

        for i in range(num_pages):

            bggURL = BGG_GAME_LIST_PAGE + str(i + 1)

            print('Scraping: ' + bggURL)

            r = requests.get(bggURL)

            soup = BeautifulSoup(r.text, 'html.parser')

            list_of_games = soup.select('#row_')

            for game in list_of_games:

                game_info = get_game_info(game)

                # If we've reached the number of games requested mid page
                if int(game_info[0]) == int(num_games):

                    csv_file.write( '\t'.join(game_info).encode('utf-8'))

                    csv_file.close()

                    stop_time = time.time()

                    total_time = stop_time - start_time

                    print('Total time to scrape: ' +\
                           str(total_time) + ' seconds ('+\
                           str(total_time/60.) +' minutes)')

                    return

                csv_file.write( '\t'.join(game_info).encode('utf-8') + '\n') 

            # So I don't get blacklisted on bgg...
            # time to wait between requests 
            time.sleep(WAIT_TIME_BETWEEN_REQUESTS)

def get_game_info(game):
    '''
    Scrapes the relevant information from the boardgame ranking pages

    Must be given a Tag generated by BeautifulSoup

    returns all the relevant data back as unicode text
    '''

    # Get games rank
    rank      = game.select_one('.collection_rank')
    rank      = rank.text.strip()

    name_ref  = game.select_one('.collection_objectname').find('a')

    # Get board game name
    name      = name_ref.text

    # Get hyperlink to board games webpage on bgg
    reference = name_ref['href']

    # Get year the game was published
    try:
        pub_year  = game.select_one('.collection_objectname').find('span').text
        pub_year  = pub_year.strip('()')

    # In case there is no year provided
    except AttributeError:
        pub_year  = u'N/A'

    g_rating, a_rating, num_voters = game.select('.collection_bggrating')

    # Get Geek Rating
    g_rating  = g_rating.text.strip()

    # Get Average Rating
    a_rating  = a_rating.text.strip()

    # Get Number of Voters (for the Average Rating)
    num_voters= num_voters.text.strip()

    return rank, name, reference, pub_year, g_rating, a_rating, num_voters

